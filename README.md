# KnoAD-Net: Knowledge-Augmented Alzheimer's Detection Network

<div align="center">

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

**Multi-Modal Deep Learning for Alzheimer's Disease Detection with Explainable AI**

[Documentation](docs/PROJECT_DOCUMENTATION.md) â€¢ [Architecture](ARCHITECTURE.md) â€¢ [Contributing](CONTRIBUTING.md) â€¢ [Changelog](CHANGELOG.md)

</div>

---

## ğŸ¯ Overview

**KnoAD-Net** is an advanced deep learning system for early detection and classification of Alzheimer's Disease (AD) that combines:

- ğŸ§  **Multi-Modal Learning**: Integrates MRI brain imaging with clinical/tabular features
- ğŸ”„ **Cross-Modal Attention**: Learns complex relationships between imaging and clinical data
- ğŸ“š **Retrieval-Augmented Generation (RAG)**: Provides explainable, evidence-based diagnostic reasoning
- ğŸ‘ï¸ **Vision Transformer (ViT)**: State-of-the-art image encoding for MRI analysis
- ğŸ“ **Three-Class Classification**: Distinguishes between Cognitive Normal (CN), Mild Cognitive Impairment (MCI), and Alzheimer's Disease (AD)

### Key Features

âœ… **Explainable AI**: RAG module provides clinical justifications based on established medical guidelines  
âœ… **High Accuracy**: Achieves ~75-80% accuracy on OASIS-1 dataset  
âœ… **Multi-Modal Fusion**: Combines visual and tabular data for comprehensive assessment  
âœ… **CPU Optimized**: Configured for efficient training on AMD Ryzen 5000 processors  
âœ… **Clinical Decision Support**: Generates detailed diagnostic reports with recommendations  
âœ… **Research Ready**: Built with best practices for reproducibility and extensibility

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8 or higher
- 16GB+ RAM recommended
- Multi-core CPU (GPU optional but not required)
- 20GB+ storage for dataset and models

### Installation

```bash
# Clone the repository
git clone https://github.com/Aspect022/Alzimers-Research.git
cd Alzimers-Research

# Create and activate virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install --upgrade pip
pip install -r requirements.txt
```

### Download Dataset

1. Visit [OASIS-1 Dataset](https://www.oasis-brains.org/)
2. Register and download OASIS-1 Cross-Sectional dataset
3. Extract disc1 through disc6 to `data/raw/mri/`
4. Place `oasis_cross-sectional.csv` in `data/raw/tabular/`

### Run the Pipeline

```bash
# Option 1: Automated execution (Recommended)
python RUN_ALL_STEPS.py

# Option 2: Manual step-by-step
python convert_hdr_disc1_to_disc6.py  # Convert HDR to NIfTI
python phase1_data_pipeline.py         # Preprocess data
python phase2_baselines.py             # Train baseline models
python notebook3_knoadnet_core.py      # Train KnoAD-Net
python notebook4_rag_module.py         # Setup RAG module
python notebook5_evaluation.py         # Comprehensive evaluation
```

---

## ğŸ“Š Project Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      KnoAD-Net System                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚                                           â”‚
 â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”                                 â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
 â”‚   MRI   â”‚                                 â”‚ Clinicalâ”‚
 â”‚  Input  â”‚                                 â”‚ Featuresâ”‚
 â”‚(128x128)â”‚                                 â”‚  (9D)   â”‚
 â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                                 â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
      â”‚                                           â”‚
 â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
 â”‚ Vision      â”‚                          â”‚  Tabular     â”‚
 â”‚ Transformer â”‚                          â”‚  Encoder     â”‚
 â”‚ (ViT-Tiny)  â”‚                          â”‚ (Transformer)â”‚
 â”‚  768-dim    â”‚                          â”‚   768-dim    â”‚
 â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
      â”‚                                           â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  Cross-Modal     â”‚
            â”‚  Attention       â”‚
            â”‚  (8 heads)       â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  Fusion          â”‚
            â”‚  Classifier      â”‚
            â”‚  (3 classes)     â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   Prediction     â”‚
            â”‚  CN / MCI / AD   â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   RAG Module     â”‚
            â”‚  (ChromaDB +     â”‚
            â”‚   Clinical KB)   â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  Diagnostic      â”‚
            â”‚  Report          â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

For detailed architecture information, see [ARCHITECTURE.md](ARCHITECTURE.md).

---

## ğŸ“ Project Structure

```
Alzimers-Research/
â”‚
â”œâ”€â”€ ğŸ“‚ data/                          # Dataset (gitignored - too large)
â”‚   â”œâ”€â”€ raw/                          # Original OASIS-1 data
â”‚   â”œâ”€â”€ processed/                    # Preprocessed MRI slices
â”‚   â””â”€â”€ splits/                       # Train/val/test splits
â”‚
â”œâ”€â”€ ğŸ“‚ models/                        # Trained model weights
â”‚   â””â”€â”€ knoadnet_best.pth
â”‚
â”œâ”€â”€ ğŸ“‚ results/                       # Experiment results and metrics
â”‚   â”œâ”€â”€ comprehensive_metrics.json
â”‚   â””â”€â”€ sample_rag_report.txt
â”‚
â”œâ”€â”€ ğŸ“‚ visualizations/                # Generated plots and figures
â”‚   â””â”€â”€ attention_maps/
â”‚
â”œâ”€â”€ ğŸ“‚ rag_knowledge/                 # RAG knowledge base
â”‚   â””â”€â”€ chroma_db/                    # Vector database
â”‚
â”œâ”€â”€ ğŸ“‚ docs/                          # Detailed documentation
â”‚   â”œâ”€â”€ PROJECT_DOCUMENTATION.md      # Complete technical documentation
â”‚   â””â”€â”€ README.md                     # Documentation overview
â”‚
â”œâ”€â”€ ğŸ“„ config.py                      # Main configuration file
â”œâ”€â”€ ğŸ“„ utils.py                       # Utility functions
â”‚
â”œâ”€â”€ ğŸ“„ phase1_data_pipeline.py       # Data preprocessing pipeline
â”œâ”€â”€ ğŸ“„ phase2_baselines.py           # Baseline model training
â”œâ”€â”€ ğŸ“„ notebook3_knoadnet_core.py    # KnoAD-Net model implementation
â”œâ”€â”€ ğŸ“„ notebook4_rag_module.py       # RAG module implementation
â”œâ”€â”€ ğŸ“„ notebook5_evaluation.py       # Comprehensive evaluation
â”‚
â”œâ”€â”€ ğŸ“„ RUN_ALL_STEPS.py              # Master execution script
â”œâ”€â”€ ğŸ“„ requirements.txt               # Python dependencies
â”œâ”€â”€ ğŸ“„ README.md                      # This file
â”œâ”€â”€ ğŸ“„ LICENSE                        # Project license
â”œâ”€â”€ ğŸ“„ CONTRIBUTING.md               # Contribution guidelines
â””â”€â”€ ğŸ“„ CHANGELOG.md                  # Version history
```

---

## ğŸ§  Scientific Background

### Why Alzheimer's Disease Detection Matters

Alzheimer's Disease (AD) is a progressive neurodegenerative disorder affecting over **55 million people worldwide**. Early and accurate diagnosis is critical for:

- ğŸ¥ Initiating timely medical interventions
- ğŸ“‹ Planning appropriate long-term care
- ğŸ”¬ Enabling participation in clinical trials
- ğŸ’Š Maximizing effectiveness of disease-modifying therapies
- ğŸ‘¨â€ğŸ‘©â€ğŸ‘§ Improving quality of life for patients and caregivers

### Traditional Diagnostic Challenges

Traditional AD diagnosis relies on:

1. **Clinical Assessment**: Cognitive tests (MMSE, MoCA) - subjective and variable
2. **Neuroimaging**: MRI/PET scans - requires expert radiologist interpretation
3. **Biomarkers**: CSF analysis - expensive and invasive

**KnoAD-Net addresses these challenges** by automating MRI analysis, integrating multiple data modalities, and providing transparent, guideline-based explanations.

### Why Multi-Modal Learning?

Research demonstrates that combining imaging and clinical data significantly improves diagnostic accuracy:

- **MRI Imaging**: Captures structural brain changes (hippocampal atrophy, ventricular enlargement)
- **Clinical Features**: Provides cognitive performance (MMSE scores), demographics, genetic risk (APOE4)
- **Multi-Modal Fusion**: Captures complementary information that single modalities miss

---

## ğŸ“ˆ Performance & Results

### Expected Performance on OASIS-1 Dataset

| Metric | Baseline CNN | Baseline ResNet | **KnoAD-Net** |
|--------|--------------|-----------------|---------------|
| **Accuracy** | ~65-70% | ~70-75% | **~75-80%** |
| **F1 (CN)** | 0.72 | 0.75 | **0.78** |
| **F1 (MCI)** | 0.55 | 0.60 | **0.65** |
| **F1 (AD)** | 0.68 | 0.72 | **0.76** |

### Evaluation Metrics

- âœ… **Accuracy**: Overall classification accuracy
- âœ… **Precision/Recall/F1**: Per-class performance
- âœ… **Confusion Matrix**: Misclassification patterns
- âœ… **ROC-AUC**: One-vs-rest for each class
- âœ… **Attention Visualization**: Heatmaps showing relevant brain regions

---

## ğŸ”® Future Work

### Short-Term Improvements
- Advanced MRI-specific data augmentation
- Multi-slice/volumetric 3D input processing
- Ensemble model predictions
- Automated hyperparameter tuning

### Medium-Term Enhancements
- LLM integration for enhanced RAG explanations
- Improved attention visualization
- Longitudinal disease progression tracking
- External validation on ADNI and AIBL datasets

### Long-Term Vision
- Multi-modal extension (PET, genetic data, CSF biomarkers)
- Clinical deployment with web interface
- DICOM integration and HIPAA compliance
- Federated learning across institutions

---

## ğŸ“š Dataset Information

### OASIS-1 (Open Access Series of Imaging Studies)

- **Total Subjects**: ~112 unique subjects (disc1-disc6)
- **Age Range**: 18-96 years
- **Design**: Cross-sectional
- **MRI Format**: T1-weighted, skull-stripped, Talairach normalized
- **Clinical Features**: 9 features including Age, Sex, MMSE, Education, Brain Volume metrics

**Citation Required**: Marcus DS et al. (2007). "Open Access Series of Imaging Studies (OASIS): Cross-sectional MRI Data in Young, Middle Aged, Nondemented, and Demented Older Adults." *Journal of Cognitive Neuroscience*, 19(9):1498-1507.

---

## ğŸ¤ Contributing

We welcome contributions from the community! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details on:

- Code of conduct
- How to submit issues and pull requests
- Development setup and testing
- Code style and documentation standards

---

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

### Important Research Use Notice

âš ï¸ **IMPORTANT**: This system is for **research purposes only** and is **NOT** approved for clinical diagnosis. Always consult qualified healthcare professionals for medical decisions.

### Ethical Considerations

- **Bias**: Model performance may vary across demographics
- **Privacy**: Ensure HIPAA/GDPR compliance when using patient data
- **Transparency**: Always provide explanations alongside predictions
- **Human Oversight**: Clinical decisions must involve human experts

---

## ğŸ“ Contact & Support

### Getting Help

- ğŸ“– **Documentation**: Check [docs/PROJECT_DOCUMENTATION.md](docs/PROJECT_DOCUMENTATION.md)
- ğŸ› **Issues**: Report bugs via [GitHub Issues](https://github.com/Aspect022/Alzimers-Research/issues)
- ğŸ’¬ **Discussions**: Join community discussions
- ğŸ“§ **Contact**: Reach out via GitHub

### Troubleshooting

For common issues and solutions, see the [Troubleshooting section](docs/PROJECT_DOCUMENTATION.md#troubleshooting) in the complete documentation.

---

## ğŸ“ Acknowledgments

This project builds upon the work of:

- **OASIS Team** for providing open-access neuroimaging data
- **timm Library** (Ross Wightman) for Vision Transformer implementations
- **ChromaDB** for vector database infrastructure
- **PyTorch Team** for the deep learning framework
- **Medical AI Community** for advancing interpretable healthcare AI

---

## ğŸ“š Key References

1. **Marcus DS et al.** (2007). OASIS: Cross-sectional MRI Data. *Journal of Cognitive Neuroscience*, 19(9):1498-1507.

2. **Dosovitskiy A et al.** (2021). An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale. *ICLR*.

3. **Vaswani A et al.** (2017). Attention is All You Need. *NeurIPS*.

4. **Lewis P et al.** (2020). Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks. *NeurIPS*.

For a complete list of references, see [docs/PROJECT_DOCUMENTATION.md](docs/PROJECT_DOCUMENTATION.md#references).

---

## â­ Star History

If you find this project useful, please consider giving it a star! â­

---

<div align="center">

**Built with â¤ï¸ for Alzheimer's Research**

*Advancing AI-powered early detection and diagnosis*

</div>
